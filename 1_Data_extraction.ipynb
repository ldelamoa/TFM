{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301bfc8d",
   "metadata": {
    "id": "301bfc8d"
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from datetime import timedelta, date, datetime\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from tqdm import tqdm\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62bc02b",
   "metadata": {
    "id": "b62bc02b"
   },
   "source": [
    "## 1. Daily data extraction with yahoo finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e47947e",
   "metadata": {
    "id": "4e47947e"
   },
   "outputs": [],
   "source": [
    "tickers = ['SPY', 'IWM', 'VXUS', 'AAXJ', 'EEM', 'QQQ', 'GLD', 'AGG', 'BNDX', 'VNQ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d558e3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T11:36:11.154860700Z",
     "start_time": "2023-11-30T11:36:10.930685800Z"
    },
    "id": "0d558e3f"
   },
   "outputs": [],
   "source": [
    "def download_data_1d(tickers, end_date, start_date):\n",
    "    print(tickers)\n",
    "    print(end_date)\n",
    "    print(start_date)\n",
    "\n",
    "    # Convert dates to datetime objects with specific timezone\n",
    "    tz = pytz.timezone('America/New_York')\n",
    "    end_date_tz = tz.localize(pd.Timestamp(end_date))\n",
    "    start_date_tz = tz.localize(pd.Timestamp(start_date))\n",
    "\n",
    "    # Initialize the resulting DataFrame\n",
    "    result = pd.DataFrame()\n",
    "\n",
    "    # Download data for each ticker\n",
    "    for i, ticker in enumerate(tqdm(tickers, desc=\"Downloading data\"), start=1):\n",
    "        try:\n",
    "            data = yf.download(tickers=ticker, start=start_date, end=end_date, interval=\"1d\")\n",
    "            data['tic'] = ticker\n",
    "            data['datadate'] = data.index\n",
    "            result = pd.concat([result, data], axis=0)\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading data for {ticker}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    result.reset_index(inplace=True)\n",
    "    result['datadate'] = result['datadate'].dt.date\n",
    "    result = result.drop(columns=['Date'], axis=1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "result = download_data_1d(tickers, '2023-12-31', '2013-10-31')"
   ],
   "metadata": {
    "id": "CGTIGeitlFv3"
   },
   "id": "CGTIGeitlFv3",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e947823b",
   "metadata": {
    "id": "e947823b"
   },
   "outputs": [],
   "source": [
    "# Add info of the dividends\n",
    "filtered_dividends_total = pd.DataFrame()\n",
    "\n",
    "for ticker in tickers:\n",
    "    etf = yf.Ticker(ticker)\n",
    "\n",
    "    dividends = etf.dividends\n",
    "    filtered_dividends = dividends[\"2013-10-31\":\"2023-12-31\"]\n",
    "\n",
    "    filtered_dividends = filtered_dividends.to_frame(name=\"Dividends\")\n",
    "    filtered_dividends[\"tic\"] = ticker\n",
    "    filtered_dividends['datadate'] = filtered_dividends.index\n",
    "    filtered_dividends_total = pd.concat([filtered_dividends_total, filtered_dividends])\n",
    "\n",
    "filtered_dividends_total.reset_index(inplace=True)\n",
    "filtered_dividends_total['datadate'] = filtered_dividends_total['datadate'].dt.date\n",
    "filtered_dividends_total = filtered_dividends_total.drop(columns=['Date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133ca168",
   "metadata": {
    "id": "133ca168"
   },
   "outputs": [],
   "source": [
    "date_info = pd.merge(result, filtered_dividends_total, on = ['datadate', 'tic'], how = 'left')\n",
    "new_column_order = ['datadate', 'tic', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'Dividends']\n",
    "date_info = date_info[new_column_order]\n",
    "date_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9573be20",
   "metadata": {
    "id": "9573be20"
   },
   "source": [
    "## 2. Macroeconomic data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5add52da",
   "metadata": {
    "id": "5add52da"
   },
   "source": [
    "Links to download the csv's:\n",
    "- GDP Growth: https://data.worldbank.org/indicator/NY.GDP.MKTP.KD.ZG\n",
    "- GDP: https://data.worldbank.org/indicator/NY.GDP.MKTP.CD\n",
    "- Inflation: https://data.worldbank.org/indicator/FP.CPI.TOTL.ZG\n",
    "- Population: https://data.worldbank.org/indicator/SP.POP.TOTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116e7955",
   "metadata": {
    "id": "116e7955"
   },
   "outputs": [],
   "source": [
    "# Function to skip rows at the header of the csv's\n",
    "def load_dataset_skiprows(*, file_name: str) -> pd.DataFrame:\n",
    "    _data = pd.read_csv(file_name, skiprows=4)\n",
    "    _data= _data.drop_duplicates()\n",
    "    return _data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d39b390",
   "metadata": {
    "id": "3d39b390"
   },
   "outputs": [],
   "source": [
    "#Define the mapping of countries to their groups\n",
    "country_to_group = {\n",
    "    'United States': 'US',\n",
    "\n",
    "    'Canada': 'Developed',\n",
    "    'United Kingdom': 'Developed',\n",
    "    'Germany': 'Developed',\n",
    "    'France': 'Developed',\n",
    "    'Switzerland': 'Developed',\n",
    "    'Netherlands': 'Developed',\n",
    "    'Sweden': 'Developed',\n",
    "    'Denmark': 'Developed',\n",
    "    'Spain': 'Developed',\n",
    "    'Japan': 'Developed',\n",
    "    'South Korea': 'Developed',\n",
    "    'Australia': 'Developed',\n",
    "    'New Zealand': 'Developed',\n",
    "    'Singapore': 'Developed',\n",
    "    'Hong Kong': 'Developed',\n",
    "\n",
    "    'China': 'Emerging',\n",
    "    'India': 'Emerging',\n",
    "    'Indonesia': 'Emerging',\n",
    "    'Thailand': 'Emerging',\n",
    "    'Malaysia': 'Emerging',\n",
    "    'Phlippines': 'Emerging',\n",
    "    'Vietnam': 'Emerging',\n",
    "    'Brazil': 'Emerging',\n",
    "    'Mexico': 'Emerging',\n",
    "    'Argentina': 'Emerging',\n",
    "    'Chile': 'Emerging',\n",
    "    'Colombia': 'Emerging',\n",
    "    'Peru': 'Emerging',\n",
    "    'Poland': 'Emerging',\n",
    "    'Hungary': 'Emerging',\n",
    "    'Turkey': 'Emerging',\n",
    "    'South Africa': 'Emerging',\n",
    "    'Egypt': 'Emerging',\n",
    "    'Nigeria': 'Emerging',\n",
    "    'Saudi Arabia': 'Emerging',\n",
    "    'United Arab Emirates': 'Emerging',\n",
    "    'Qatar': 'Emerging'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd699bb7",
   "metadata": {
    "id": "bd699bb7"
   },
   "source": [
    "### 2.1. GDP Growth by groups of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a24a567",
   "metadata": {
    "id": "6a24a567"
   },
   "outputs": [],
   "source": [
    "gdp_growth_global = load_dataset_skiprows(file_name='GDP_GROWTH_GLOBAL.csv')\n",
    "selected_columns = ['Country Name'] + [str(year) for year in range(2013, 2024)]\n",
    "gdp_growth_global = gdp_growth_global[selected_columns]\n",
    "\n",
    "gdp_global = load_dataset_skiprows(file_name='GDP_GLOBAL.csv')\n",
    "selected_columns = ['Country Name'] + [str(year) for year in range(2013, 2024)]\n",
    "gdp_global = gdp_global[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec15016",
   "metadata": {
    "id": "dec15016"
   },
   "outputs": [],
   "source": [
    "gdp_growth_long = gdp_growth_global.melt(id_vars=['Country Name'], var_name='Year', value_name='GDP growth')\n",
    "gdp_long = gdp_global.melt(id_vars=['Country Name'], var_name='Year', value_name='GDP')\n",
    "\n",
    "merged_df = pd.merge(gdp_growth_long, gdp_long, on=['Country Name', 'Year'])\n",
    "merged_df['Group'] = merged_df['Country Name'].map(country_to_group)\n",
    "\n",
    "def weighted_avg(df, weight_column, value_column):\n",
    "    return (df[weight_column] * df[value_column]).sum() / df[weight_column].sum()\n",
    "\n",
    "grouped_df_growth = merged_df.groupby(['Year', 'Group']).apply(weighted_avg, 'GDP', 'GDP growth').reset_index(name='GDP_Growth')\n",
    "\n",
    "pivoted_gdp = grouped_df_growth.pivot(index='Year', columns='Group', values='GDP_Growth')\n",
    "pivoted_gdp.columns = ['GDP_growth_developed', 'GDP_growth_emerging', 'GDP_growth_us']\n",
    "pivoted_gdp = pivoted_gdp.reset_index()\n",
    "pivoted_gdp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f59900",
   "metadata": {
    "id": "f3f59900"
   },
   "source": [
    "### 2.2. Inflation by groups of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af4beee",
   "metadata": {
    "id": "9af4beee"
   },
   "outputs": [],
   "source": [
    "inflation_global = load_dataset_skiprows(file_name='INFLATION_GLOBAL.csv')\n",
    "selected_columns = ['Country Name'] + [str(year) for year in range(2013, 2024)]\n",
    "inflation_global = inflation_global[selected_columns]\n",
    "\n",
    "population_global = load_dataset_skiprows(file_name='POPULATION_GLOBAL.csv')\n",
    "selected_columns = ['Country Name'] + [str(year) for year in range(2013, 2024)]\n",
    "population_global = population_global[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ef7bc2",
   "metadata": {
    "id": "33ef7bc2"
   },
   "outputs": [],
   "source": [
    "inflation_long = inflation_global.melt(id_vars=['Country Name'], var_name='Year', value_name='Inflation')\n",
    "population_long = population_global.melt(id_vars=['Country Name'], var_name='Year', value_name='Population')\n",
    "\n",
    "merged_df = pd.merge(inflation_long, population_long, on=['Country Name', 'Year'])\n",
    "merged_df['Group'] = merged_df['Country Name'].map(country_to_group)\n",
    "\n",
    "def weighted_avg(df, weight_column, value_column):\n",
    "    return (df[weight_column] * df[value_column]).sum() / df[weight_column].sum()\n",
    "\n",
    "grouped_inflation_df = merged_df.groupby(['Year', 'Group']).apply(weighted_avg, 'Population', 'Inflation').reset_index(name='Inflation')\n",
    "\n",
    "pivoted_inflation = grouped_inflation_df.pivot(index='Year', columns='Group', values='Inflation')\n",
    "pivoted_inflation.columns = ['inflation_developed', 'inflation_emerging', 'inflation_us']\n",
    "pivoted_inflation = pivoted_inflation.reset_index()\n",
    "pivoted_inflation.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308b0221",
   "metadata": {
    "id": "308b0221"
   },
   "source": [
    "### 2.3 Join info and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8e9276",
   "metadata": {
    "id": "7e8e9276"
   },
   "outputs": [],
   "source": [
    "date_info['Year'] = pd.to_datetime(date_info['datadate']).dt.year\n",
    "\n",
    "macroeconomic_data = pd.merge(pivoted_gdp, pivoted_inflation, on = ['Year'], how = 'left')\n",
    "macroeconomic_data['Year'] = macroeconomic_data['Year'].astype(int)\n",
    "all_info = pd.merge(date_info, macroeconomic_data, on='Year', how='left')\n",
    "all_info = all_info.drop(columns=['Year'], axis=1)\n",
    "all_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de3a5ae",
   "metadata": {
    "id": "8de3a5ae"
   },
   "outputs": [],
   "source": [
    "all_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a6478d",
   "metadata": {
    "id": "35a6478d"
   },
   "outputs": [],
   "source": [
    "all_info.to_csv(\"datos_1d.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e0370a",
   "metadata": {
    "id": "b7e0370a"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
